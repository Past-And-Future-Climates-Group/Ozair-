{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092ea89c-12f6-403c-af18-7a2a52d0f8ac",
   "metadata": {},
   "source": [
    "## Santa Barbara Climate Dashboard Showing Model Projections for Gridboxes in Santa Barbara County Extracted from Netcdf Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94064ad0-eb95-41ea-9a4e-d8967e9f2d74",
   "metadata": {},
   "source": [
    "#### Last time, I developed a skeleton dashboard showing campus point annual average minimum temperature data; however, the model projections weren't from the latest assessment report. For this week, I updated the dashboard to include data from Cal-Adapt using this download data tool link https://cal-adapt-3.vercel.app/dashboard/data-download-tool. This updated dashboard includes a dropdown menu for users to select a specific grid box in Santa Barbara with specific latitude/longitude coordinates. Once a grid box is selected, annual average minimum and maximum temperature line plots will be shown from 2015 to 2100 using the TaiESM1 model. The respective net CDF files shown in the code have data for daily minimum/maximum air temperatures; however, my code calculated the annual average for a specific year by averaging out the data points for each day in a year and dividing them by the number of years. My data shows annual average minimum/maximum temperature projections for each grid box from 2015 to 2100. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cb5419-1f47-4c09-9f2b-8c44053934a6",
   "metadata": {},
   "source": [
    "#### Some gridboxes don't show data once they are selected since no data may be available from that gridbox and/or that gridbox encompasses the ocean. I also connected shiny to vscode to update the dashboard, and once the dashboard is fully developed, I can develop a web link that shows the dashboard from shiny for python. This week, I want to work on updating the dashboard to show every single climate variable as mentioned before, with different ssp scenario options/ for every single gridbox. So by the end of this week, I hope to develop a fully working mini climate dashboard for Santa Barbara. I also want to make the location data map more user friendly by turning the map gridboxes into clear, noticeable buttons for users to extract data from instead of a dropdown menu. I also want to include observational data for each climate variable like what is shown for the campus point. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641247a3-43bf-4884-8e6a-441db278710f",
   "metadata": {},
   "source": [
    "#### The following code extracts data from two netCDF files. The campus point data page is kept intact; however, the location data page has been updated to show a map of Santa Barbara County with all the grid boxes. Users can select a grid box and view plots for annual average minimum and maximum temperature projections from 2015 to 2100 for that specific grid box. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5850f4e1-782e-4188-9039-80d6e3819551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9y/cmg0_lnj3y1b07xwqw5nvmv80000gn/T/ipykernel_14153/901180878.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: NetCDF file not found. Make sure '/Users/ozairusmani/Summer 2025 REU/06083_tasmin_day_TaiESM1_ssp370_r1i1p1f1.nc' is in the correct directory.\n"
     ]
    }
   ],
   "source": [
    "from shiny import App, ui, render, reactive\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "from shinywidgets import output_widget, render_widget\n",
    "\n",
    "# --- Constants and File Paths ---\n",
    "# NetCDF file paths for minimum and maximum daily air surface temperature\n",
    "NETCDF_FILE_TASMIN = \"06083_tasmin_day_TaiESM1_ssp370_r1i1p1f1.nc\"\n",
    "NETCDF_FILE_TASMAX = \"06083_tasmax_day_TaiESM1_ssp370_r1i1p1f1.nc\"\n",
    "\n",
    "# Latitude and Longitude bounds for the Santa Barbara region\n",
    "SB_LAT_MIN, SB_LAT_MAX = 33.8, 35.2\n",
    "SB_LON_MIN, SB_LON_MAX = -120.9, -119.3 # Note: NetCDF longitudes might be 0-360, adjust for -180 to 180 if needed\n",
    "\n",
    "# Global variables to store loaded NetCDF datasets\n",
    "netcdf_ds_tasmin = None\n",
    "netcdf_ds_tasmax = None\n",
    "\n",
    "# --- Load NetCDF datasets once globally ---\n",
    "def load_netcdfs():\n",
    "    \"\"\"\n",
    "    Loads the global NetCDF datasets for minimum and maximum temperature.\n",
    "    This function is called once when the application starts to ensure\n",
    "    the data is available for all sessions. It handles FileNotFoundError.\n",
    "    \"\"\"\n",
    "    global netcdf_ds_tasmin, netcdf_ds_tasmax\n",
    "    # Only load if they haven't been loaded already (e.g., on app restart)\n",
    "    if netcdf_ds_tasmin is None or netcdf_ds_tasmax is None:\n",
    "        try:\n",
    "            netcdf_ds_tasmin = xr.open_dataset(NETCDF_FILE_TASMIN)\n",
    "            netcdf_ds_tasmax = xr.open_dataset(NETCDF_FILE_TASMAX)\n",
    "            print(\"NetCDF datasets loaded successfully.\")\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"ERROR: NetCDF file not found. Make sure '{e.filename}' is in the correct directory.\")\n",
    "            # Initialize as empty Datasets to prevent further errors\n",
    "            netcdf_ds_tasmin = xr.Dataset()\n",
    "            netcdf_ds_tasmax = xr.Dataset()\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while loading NetCDF files: {e}\")\n",
    "            netcdf_ds_tasmin = xr.Dataset()\n",
    "            netcdf_ds_tasmax = xr.Dataset()\n",
    "\n",
    "# Call the function to load NetCDF data when the script starts\n",
    "load_netcdfs()\n",
    "\n",
    "# --- Load CSV Data ---\n",
    "def load_csv_minimum_temperature_data():\n",
    "    \"\"\"\n",
    "    Loads minimum temperature data from a CSV file.\n",
    "    It searches for 'chart.csv', 'chart (1).csv', or 'chart1.csv' in the current\n",
    "    directory and its subdirectories. It attempts to read the CSV, skipping\n",
    "    the first 8 rows if necessary, and renames columns by stripping whitespace.\n",
    "    It also converts the 'year' column to numeric and handles missing values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        possible_filenames = ['chart.csv', 'chart (1).csv', 'chart1.csv']\n",
    "        found_path = None\n",
    "        # Walk through the current directory and its subdirectories to find the CSV\n",
    "        for root, _, files in os.walk(\".\"):\n",
    "            for f in files:\n",
    "                if f in possible_filenames:\n",
    "                    found_path = os.path.join(root, f)\n",
    "                    break\n",
    "            if found_path:\n",
    "                break\n",
    "        if not found_path:\n",
    "            raise FileNotFoundError(\"No CSV file matching expected names found.\")\n",
    "        \n",
    "        # Attempt to read CSV, first skipping 8 rows, then without skipping\n",
    "        try:\n",
    "            df = pd.read_csv(found_path, skiprows=8)\n",
    "        except Exception:\n",
    "            df = pd.read_csv(found_path)\n",
    "\n",
    "        # Clean column names by stripping whitespace\n",
    "        df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "        # Convert the first column to 'year' and ensure it's numeric\n",
    "        df[\"year\"] = pd.to_numeric(df.iloc[:, 0], errors=\"coerce\")\n",
    "        # Drop rows where 'year' is NaN (conversion failed)\n",
    "        df.dropna(subset=[\"year\"], inplace=True)\n",
    "        df[\"year\"] = df[\"year\"].astype(int) # Convert 'year' to integer\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Utility Functions for NetCDF Data ---\n",
    "def find_nearest_gridpoint(lat_arr, lon_arr, target_lat, target_lon):\n",
    "    \"\"\"\n",
    "    Finds the indices of the grid point nearest to the target latitude and longitude.\n",
    "    Args:\n",
    "        lat_arr (np.array): Array of latitudes from the dataset.\n",
    "        lon_arr (np.array): Array of longitudes from the dataset.\n",
    "        target_lat (float): The target latitude.\n",
    "        target_lon (float): The target longitude (can be 0-360 or -180 to 180).\n",
    "    Returns:\n",
    "        tuple: (lat_idx, lon_idx) of the nearest grid point.\n",
    "    \"\"\"\n",
    "    # Adjust target_lon to match the 0-360 range if lon_arr is in that range\n",
    "    # Assuming lon_arr is primarily 0-360, convert target_lon if it's negative\n",
    "    if np.any(lon_arr > 180) and target_lon < 0:\n",
    "        target_lon += 360\n",
    "    # If lon_arr is -180 to 180, and target_lon is > 180 (from dropdown), convert it\n",
    "    elif np.any(lon_arr < 0) and target_lon > 180:\n",
    "        target_lon -= 360\n",
    "\n",
    "    lat_idx = (np.abs(lat_arr - target_lat)).argmin()\n",
    "    lon_idx = (np.abs(lon_arr - target_lon)).argmin()\n",
    "    return lat_idx, lon_idx\n",
    "\n",
    "def extract_timeseries(ds, lat_idx, lon_idx, variable_name=None, years_limit=None):\n",
    "    \"\"\"\n",
    "    Extracts a time series for a specific grid point from an xarray Dataset.\n",
    "    Args:\n",
    "        ds (xr.Dataset): The xarray Dataset.\n",
    "        lat_idx (int): Latitude index of the grid point.\n",
    "        lon_idx (int): Longitude index of the grid point.\n",
    "        variable_name (str, optional): The name of the variable to extract.\n",
    "                                       If None, attempts to extract the first variable.\n",
    "        years_limit (int, optional): If provided, limits the data to the last N years\n",
    "                                     from the current date.\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with 'Date' and the extracted variable's values.\n",
    "    \"\"\"\n",
    "    if \"time\" not in ds.coords:\n",
    "        print(\"Error: 'time' coordinate not found in dataset.\")\n",
    "        return pd.DataFrame({\"Date\": [], \"No Data\": []})\n",
    "\n",
    "    times = pd.to_datetime(ds[\"time\"].values)\n",
    "    \n",
    "    time_mask = np.full(len(times), True)\n",
    "    if years_limit is not None:\n",
    "        max_date = pd.Timestamp.now()\n",
    "        min_date = max_date - pd.Timedelta(days=365*years_limit)\n",
    "        time_mask = (times >= min_date) & (times <= max_date)\n",
    "\n",
    "    var_to_extract = None\n",
    "    if variable_name and variable_name in ds.data_vars:\n",
    "        var_to_extract = variable_name\n",
    "    elif ds.data_vars:\n",
    "        var_to_extract = list(ds.data_vars.keys())[0] # Fallback to first variable\n",
    "\n",
    "    if var_to_extract is None:\n",
    "        print(\"Error: No variable to extract found in dataset.\")\n",
    "        return pd.DataFrame({\"Date\": [], \"No Data\": []})\n",
    "\n",
    "    # Check if the variable has the expected dimensions (time, lat, lon)\n",
    "    if ds[var_to_extract].ndim < 3 or ds[var_to_extract].dims[0] != 'time':\n",
    "        print(f\"Warning: Variable '{var_to_extract}' does not have expected dimensions (time, lat, lon).\")\n",
    "        return pd.DataFrame({\"Date\": [], \"No Data\": []})\n",
    "\n",
    "    # Extract values for the specific grid point\n",
    "    values = ds[var_to_extract][:, lat_idx, lon_idx].values\n",
    "    \n",
    "    # Ensure values are numeric\n",
    "    if np.issubdtype(values.dtype, np.number):\n",
    "        values = values[time_mask]\n",
    "    else:\n",
    "        print(f\"Warning: Variable '{var_to_extract}' contains non-numeric data.\")\n",
    "        return pd.DataFrame({\"Date\": [], \"No Data\": []})\n",
    "\n",
    "    filtered_times = times[time_mask]\n",
    "    if len(filtered_times) == 0 or len(values) == 0:\n",
    "        print(\"No data points after filtering by time or for the selected grid point.\")\n",
    "        return pd.DataFrame({\"Date\": [], \"No Data\": []})\n",
    "        \n",
    "    df = pd.DataFrame({\"Date\": filtered_times, var_to_extract: values})\n",
    "    return df\n",
    "\n",
    "def get_gridbox_choices(ds, step=1):\n",
    "    \"\"\"\n",
    "    Generates a list of gridbox choices (latitude, longitude strings)\n",
    "    within the Santa Barbara bounds from an xarray Dataset.\n",
    "    Args:\n",
    "        ds (xr.Dataset): The xarray Dataset.\n",
    "        step (int): Step size to sample grid points (e.g., 1 for all, 5 for every 5th).\n",
    "    Returns:\n",
    "        list: A list of strings like \"lat,lon\" for dropdown choices.\n",
    "    \"\"\"\n",
    "    if not all(coord in ds.coords for coord in [\"lat\", \"lon\"]):\n",
    "        print(\"Error: 'lat' or 'lon' coordinates not found in dataset for gridbox choices.\")\n",
    "        return []\n",
    "        \n",
    "    lats = ds[\"lat\"].values\n",
    "    lons = ds[\"lon\"].values\n",
    "    choices = []\n",
    "    for i_lat in range(0, len(lats), step):\n",
    "        lat = lats[i_lat]\n",
    "        if not (SB_LAT_MIN <= lat <= SB_LAT_MAX):\n",
    "            continue # Skip latitudes outside Santa Barbara bounds\n",
    "        for i_lon in range(0, len(lons), step):\n",
    "            lon = lons[i_lon]\n",
    "            # Adjust longitude for checking against SB_LON_MIN/MAX if it's in 0-360 range\n",
    "            lon_check = lon - 360 if lon > 180 else lon\n",
    "            if not (SB_LON_MIN <= lon_check <= SB_LON_MAX):\n",
    "                continue # Skip longitudes outside Santa Barbara bounds\n",
    "            choices.append(f\"{lat:.3f},{lon:.3f}\")\n",
    "    return choices\n",
    "\n",
    "# --- UI Definition ---\n",
    "app_ui = ui.page_fluid(\n",
    "    # Custom CSS for styling the dashboard\n",
    "    ui.tags.head(\n",
    "        ui.tags.style(\"\"\"\n",
    "            body {\n",
    "                font-family: 'Inter', sans-serif;\n",
    "                background-color: #f8f9fa;\n",
    "                color: #333;\n",
    "            }\n",
    "            .custom-card {\n",
    "                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "                color: white;\n",
    "                border-radius: 15px;\n",
    "                padding: 20px;\n",
    "                margin: 10px 0;\n",
    "                box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "            }\n",
    "            .metric-card {\n",
    "                background: white;\n",
    "                border-radius: 10px;\n",
    "                padding: 15px;\n",
    "                margin: 10px 0;\n",
    "                box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n",
    "                border-left: 4px solid #667eea;\n",
    "            }\n",
    "            .text-center {\n",
    "                text-align: center;\n",
    "            }\n",
    "            .text-muted {\n",
    "                color: #6c757d;\n",
    "            }\n",
    "            .container {\n",
    "                max-width: 960px;\n",
    "                margin: auto;\n",
    "                padding: 20px;\n",
    "                background-color: #fff;\n",
    "                border-radius: 8px;\n",
    "                box-shadow: 0 0 10px rgba(0,0,0,0.05);\n",
    "                margin-top: 20px;\n",
    "                margin-bottom: 20px;\n",
    "            }\n",
    "            h2 {\n",
    "                font-size: 2.5rem;\n",
    "                margin-bottom: 20px;\n",
    "                color: #2c3e50;\n",
    "                text-shadow: 1px 1px 2px rgba(0,0,0,0.1);\n",
    "            }\n",
    "            h3 {\n",
    "                font-size: 2rem;\n",
    "                margin-top: 20px;\n",
    "                margin-bottom: 15px;\n",
    "                color: #34495e;\n",
    "            }\n",
    "            h4 {\n",
    "                font-size: 1.5rem;\n",
    "                margin-top: 15px;\n",
    "                margin-bottom: 10px;\n",
    "                color: #34495e;\n",
    "            }\n",
    "            ul {\n",
    "                list-style-type: disc;\n",
    "                margin-left: 20px;\n",
    "            }\n",
    "            li {\n",
    "                margin-bottom: 5px;\n",
    "            }\n",
    "            hr {\n",
    "                border-top: 1px solid #eee;\n",
    "                margin: 20px 0;\n",
    "            }\n",
    "            .shiny-input-container {\n",
    "                margin-bottom: 15px;\n",
    "            }\n",
    "            .js-plotly-plot {\n",
    "                margin-top: 20px;\n",
    "                border: 1px solid #e0e0e0;\n",
    "                border-radius: 8px;\n",
    "                overflow: hidden;\n",
    "            }\n",
    "        \"\"\")\n",
    "    ),\n",
    "    # Main title of the dashboard\n",
    "    ui.h2(\"🌊 Santa Barbara Climate Data Dashboard\", class_=\"text-center\"),\n",
    "    # Data source information\n",
    "    ui.div(\n",
    "        ui.p(\"📊 Data Source: Cal-Adapt CSV & NetCDF\", class_=\"text-center text-muted\"),\n",
    "        class_=\"data-source\"\n",
    "    ),\n",
    "    # Navigation tabs for different sections of the dashboard\n",
    "    ui.navset_tab(\n",
    "        ui.nav_panel(\"🏠 Welcome\",\n",
    "            ui.div(\n",
    "                ui.h3(\"Welcome!\", class_=\"text-center\"),\n",
    "                ui.p(\"Explore Santa Barbara's climate using Cal-Adapt data.\", class_=\"text-center\"),\n",
    "                class_=\"container\"\n",
    "            )\n",
    "        ),\n",
    "        ui.nav_panel(\"📚 User Guide / Glossary / About\",\n",
    "            ui.div(\n",
    "                ui.h4(\"User Guide\"),\n",
    "                ui.tags.ul([\n",
    "                    ui.tags.li(\"Navigate to 'Location Map with Dropdown' tab to explore NetCDF data.\"),\n",
    "                    ui.tags.li(\"On the map, blue lines indicate grid cells. The red box outlines the Santa Barbara region.\"),\n",
    "                    ui.tags.li(\"Use the 'Select a Gridbox' dropdown to choose a specific grid cell for detailed temperature plots.\"),\n",
    "                    ui.tags.li(\"Navigate to 'Campus Point Data' tab to explore CSV data.\"),\n",
    "                    ui.tags.li(\"Select 'Minimum/Maximum Temperature Projections' as Data Type.\"),\n",
    "                    ui.tags.li(\"Select 'Annual Averages' as Temperature Data Type.\"),\n",
    "                    ui.tags.li(\"Use the year range slider and column checkboxes to explore the CSV data.\"),\n",
    "                ]),\n",
    "                ui.hr(),\n",
    "                ui.h4(\"Glossary\"),\n",
    "                ui.p(\"Cal-Adapt: California’s climate planning platform, providing climate change research and data.\"),\n",
    "                ui.p(\"NetCDF: Network Common Data Form, a set of interfaces for array-oriented data.\"),\n",
    "                ui.p(\"xarray: Python library for working with labeled multi-dimensional arrays, often used with NetCDF.\"),\n",
    "                ui.p(\"tasmin: Daily minimum near-surface air temperature (from NetCDF).\"),\n",
    "                ui.p(\"tasmax: Daily maximum near-surface air temperature (from NetCDF).\"),\n",
    "                ui.p(\"SSP370: Shared Socioeconomic Pathway 3-7.0, a scenario representing a medium-to-high challenge to mitigation and adaptation.\"),\n",
    "                ui.p(\"RCP 8.5: Representative Concentration Pathway 8.5, a high greenhouse gas emission scenario (from CSV).\"),\n",
    "                ui.p(\"RCP 4.5: Representative Concentration Pathway 4.5, an intermediate greenhouse gas emission scenario (from CSV).\"),\n",
    "                ui.p(\"CanESM2, CNRM-CM5, HadGEM2-ES, MIROC5: Different climate models used for projections.\"),\n",
    "                class_=\"container\"\n",
    "            )\n",
    "        ),\n",
    "        ui.nav_panel(\"📍 Location Map with Dropdown\",\n",
    "            ui.div(\n",
    "                ui.h3(\"Explore Climate Data by Grid Location\"),\n",
    "                ui.p(\"Select a gridbox on the map or from the dropdown to view detailed temperature projections.\"),\n",
    "                output_widget(\"gridbox_map\"), # Plotly mapbox for grid visualization\n",
    "                ui.output_ui(\"gridbox_dropdown_ui\"), # Dropdown for selecting gridbox\n",
    "                ui.output_text(\"selected_gridbox_info\"), # Displays info about selected gridbox\n",
    "                ui.h4(\"Annual Average Minimum Air Surface Temperature (NetCDF)\"),\n",
    "                output_widget(\"selected_gridbox_tasmin_plot\"), # Plot for tasmin data\n",
    "                ui.h4(\"Annual Average Maximum Air Surface Temperature (NetCDF)\"),\n",
    "                output_widget(\"selected_gridbox_tasmax_plot\"), # Plot for tasmax data\n",
    "                class_=\"container\"\n",
    "            )\n",
    "        ),\n",
    "        # Campus Point Data panel (CSV strictly)\n",
    "        ui.nav_panel(\"📊 Campus Point Data\",\n",
    "            ui.div(\n",
    "                ui.h3(\"Campus Point Climate Data\"),\n",
    "                ui.p(\"This section visualizes historical and projected climate data specifically for Campus Point from CSV sources.\"),\n",
    "                ui.input_select(\"location\", \"Select Location:\", choices=[\"Campus Point\"]),\n",
    "                ui.input_select(\"data_type\", \"Select Data Type:\", choices=[\n",
    "                    \"Minimum/Maximum Temperature Projections\",\n",
    "                    \"Precipitation\", \"Sea Level Rise\", \"Droughts\", \"Wildfires\"\n",
    "                ]),\n",
    "                ui.output_ui(\"temp_subcategory_ui\"), # Dynamic UI for temperature subcategories\n",
    "                ui.output_ui(\"graph_controls_ui\"), # Dynamic UI for graph controls (slider, checkboxes)\n",
    "                output_widget(\"climate_plot\"), # Plotly plot for CSV data\n",
    "                class_=\"container\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# --- Server Logic ---\n",
    "def server(input, output, session):\n",
    "    # Reactive value to store the loaded CSV data\n",
    "    csv_data = reactive.Value(None)\n",
    "    # Reactive value to store the currently selected gridbox (lat, lon) from dropdown\n",
    "    selected_gridbox = reactive.Value(None)\n",
    "    # Reactive value for the SSP scenario (currently fixed to ssp370 as per file names)\n",
    "    selected_ssp = reactive.Value(\"ssp370\") # This could be made an input if multiple SSP files are available\n",
    "\n",
    "    @reactive.Effect\n",
    "    def load_csv_once():\n",
    "        \"\"\"\n",
    "        Loads the CSV data once when the app starts or when `csv_data` is None.\n",
    "        \"\"\"\n",
    "        if csv_data.get() is None:\n",
    "            df = load_csv_minimum_temperature_data()\n",
    "            csv_data.set(df)\n",
    "            if df is None:\n",
    "                print(\"Failed to load CSV data.\")\n",
    "\n",
    "    # --- Location Map Logic (NetCDF) -----------------------------------\n",
    "    @output\n",
    "    @render_widget\n",
    "    def gridbox_map():\n",
    "        \"\"\"\n",
    "        Renders an interactive Plotly Mapbox displaying grid points\n",
    "        within the Santa Barbara region and the county boundary.\n",
    "        \"\"\"\n",
    "        ds = netcdf_ds_tasmin # Use tasmin dataset for map grid points\n",
    "        if ds is None or not all(coord in ds.coords for coord in [\"lat\", \"lon\"]):\n",
    "            fig = go.Figure()\n",
    "            fig.add_annotation(text=\"NetCDF files not loaded or missing coordinates. Please check server logs.\", x=0.5, y=0.5, showarrow=False)\n",
    "            return fig\n",
    "\n",
    "        lats = ds[\"lat\"].values\n",
    "        lons_orig = ds[\"lon\"].values # Original longitudes (can be 0-360)\n",
    "        # Convert longitudes to -180 to 180 range for Plotly Mapbox\n",
    "        lons_plot = np.where(lons_orig > 180, lons_orig - 360, lons_orig)\n",
    "\n",
    "        # Calculate half-step for drawing grid cell boundaries\n",
    "        delta_lat = (lats[1] - lats[0]) / 2 if len(lats) > 1 else 0.1\n",
    "        delta_lon = (lons_plot[1] - lons_plot[0]) / 2 if len(lons_plot) > 1 else 0.1\n",
    "        \n",
    "        lat_list, lon_list, custom_data_list = [], [], []\n",
    "        # Iterate through grid points to draw bounding boxes\n",
    "        for i, lat in enumerate(lats):\n",
    "            for j, lon_plot in enumerate(lons_plot):\n",
    "                # Check if the grid point is within the Santa Barbara bounds\n",
    "                original_lon_for_check = lons_orig[j]\n",
    "                if original_lon_for_check > 180:\n",
    "                    original_lon_for_check -= 360 # Adjust for check\n",
    "                \n",
    "                if not (SB_LAT_MIN <= lat <= SB_LAT_MAX and SB_LON_MIN <= original_lon_for_check <= SB_LON_MAX):\n",
    "                    continue # Skip grid points outside the defined bounds\n",
    "                \n",
    "                # Define corners of the grid cell\n",
    "                lat0, lat1 = lat - delta_lat, lat + delta_lat\n",
    "                lon0, lon1 = lon_plot - delta_lon, lon_plot + delta_lon\n",
    "                \n",
    "                # Add points for the grid cell rectangle\n",
    "                lat_list.extend([lat0, lat0, lat1, lat1, lat0, None])\n",
    "                lon_list.extend([lon0, lon1, lon1, lon0, lon0, None])\n",
    "                \n",
    "                # Store original lat/lon for hover information\n",
    "                custom_data_list.extend([(lat, lons_orig[j])] * 6)\n",
    "\n",
    "        # Define Santa Barbara county boundary for visualization\n",
    "        county_lat = [SB_LAT_MIN, SB_LAT_MIN, SB_LAT_MAX, SB_LAT_MAX, SB_LAT_MIN, None]\n",
    "        county_lon = [SB_LON_MIN, SB_LON_MAX, SB_LON_MAX, SB_LON_MIN, SB_LON_MIN, None]\n",
    "\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Add grid lines trace\n",
    "        fig.add_trace(go.Scattermapbox(\n",
    "            lat=lat_list, \n",
    "            lon=lon_list, \n",
    "            mode=\"lines\", \n",
    "            line=dict(width=1.5, color=\"blue\"), \n",
    "            hoverinfo=\"text\",\n",
    "            customdata=custom_data_list,\n",
    "            hovertemplate=\"<b>Gridbox:</b><br>Latitude: %{customdata[0]:.3f}<br>Longitude: %{customdata[1]:.3f}<extra></extra>\",\n",
    "            showlegend=False,\n",
    "            name=\"Grid Cells\"\n",
    "        ))\n",
    "        \n",
    "        # Add Santa Barbara county boundary trace\n",
    "        fig.add_trace(go.Scattermapbox(\n",
    "            lat=county_lat, \n",
    "            lon=county_lon, \n",
    "            mode=\"lines\", \n",
    "            line=dict(width=2, color=\"red\"), \n",
    "            hoverinfo=\"skip\", \n",
    "            showlegend=False, \n",
    "            opacity=0.7,\n",
    "            name=\"SB County Boundary\"\n",
    "        ))\n",
    "        \n",
    "        # Update map layout\n",
    "        fig.update_layout(\n",
    "            mapbox_style=\"open-street-map\", \n",
    "            mapbox_center={\"lat\": (SB_LAT_MIN + SB_LAT_MAX) / 2, \"lon\": (SB_LON_MIN + SB_LON_MAX) / 2}, \n",
    "            mapbox_zoom=8, \n",
    "            margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n",
    "            height=500 # Set a fixed height for the map\n",
    "        )\n",
    "        return fig\n",
    "\n",
    "    @output\n",
    "    @render.ui\n",
    "    def gridbox_dropdown_ui():\n",
    "        \"\"\"\n",
    "        Renders a dropdown UI element with choices for gridboxes within the SB region.\n",
    "        \"\"\"\n",
    "        ds = netcdf_ds_tasmin # Use tasmin dataset for grid choices\n",
    "        choices = get_gridbox_choices(ds, step=1) # Get all gridbox choices\n",
    "        return ui.input_select(\"gridbox_dropdown\", \"Select a Gridbox:\", choices=choices, selected=choices[0] if choices else None)\n",
    "\n",
    "    @reactive.Effect\n",
    "    def update_selected_gridbox():\n",
    "        \"\"\"\n",
    "        Updates the `selected_gridbox` reactive value when the dropdown selection changes.\n",
    "        \"\"\"\n",
    "        sel = input.gridbox_dropdown()\n",
    "        if sel:\n",
    "            lat_str, lon_str = sel.split(\",\")\n",
    "            selected_gridbox.set((float(lat_str), float(lon_str)))\n",
    "\n",
    "    @output\n",
    "    @render.text\n",
    "    def selected_gridbox_info():\n",
    "        \"\"\"\n",
    "        Displays the latitude and longitude of the currently selected gridbox.\n",
    "        \"\"\"\n",
    "        val = selected_gridbox.get()\n",
    "        if val:\n",
    "            return f\"Selected Gridbox: Latitude {val[0]:.3f}, Longitude {val[1]:.3f}\"\n",
    "        return \"Select a gridbox from the dropdown.\"\n",
    "\n",
    "    @reactive.Calc\n",
    "    def _grid_indices():\n",
    "        \"\"\"\n",
    "        Calculates the latitude and longitude indices for the selected gridbox\n",
    "        from the NetCDF datasets.\n",
    "        \"\"\"\n",
    "        val = selected_gridbox.get()\n",
    "        if val is None or netcdf_ds_tasmin is None or netcdf_ds_tasmax is None or \\\n",
    "           not all(c in netcdf_ds_tasmin.coords for c in [\"lat\", \"lon\"]):\n",
    "            return None, None, None, None # Removed the extra None from the return\n",
    "\n",
    "        target_lat, target_lon_dropdown = val[0], val[1]\n",
    "        lats_ds = netcdf_ds_tasmin[\"lat\"].values\n",
    "        lons_ds = netcdf_ds_tasmin[\"lon\"].values\n",
    "\n",
    "        lat_idx, lon_idx = find_nearest_gridpoint(lats_ds, lons_ds, target_lat, target_lon_dropdown)\n",
    "        \n",
    "        # Corrected return statement to include target_lat and target_lon_dropdown\n",
    "        return lat_idx, lon_idx, target_lat, target_lon_dropdown\n",
    "\n",
    "    @output\n",
    "    @render_widget\n",
    "    def selected_gridbox_tasmin_plot():\n",
    "        \"\"\"\n",
    "        Renders a Plotly line plot of annual average minimum air surface temperature\n",
    "        for the selected gridbox from the NetCDF data.\n",
    "        Converts Kelvin to Fahrenheit if necessary.\n",
    "        \"\"\"\n",
    "        lat_idx, lon_idx, target_lat, target_lon_dropdown = _grid_indices()\n",
    "        ssp = selected_ssp.get()\n",
    "        model = netcdf_ds_tasmin.attrs.get(\"source_id\", \"Unknown Model\")\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        if lat_idx is None or lon_idx is None:\n",
    "            fig.add_annotation(text=\"Select a gridbox to view data.\", x=0.5, y=0.5, showarrow=False)\n",
    "            return fig\n",
    "\n",
    "        df_tasmin_raw = extract_timeseries(netcdf_ds_tasmin, lat_idx, lon_idx, variable_name=\"tasmin\")\n",
    "        tasmin_units_original = netcdf_ds_tasmin['tasmin'].attrs.get('units', 'Units Unknown')\n",
    "        df_tasmin = df_tasmin_raw.copy()\n",
    "\n",
    "        tasmin_display_units = tasmin_units_original\n",
    "        # Convert Kelvin to Fahrenheit if units are Kelvin\n",
    "        if \"tasmin\" in df_tasmin.columns and tasmin_units_original.lower() in ['k', 'kelvin']:\n",
    "            df_tasmin[\"tasmin\"] = (df_tasmin[\"tasmin\"] - 273.15) * 9/5 + 32\n",
    "            tasmin_display_units = '°F'\n",
    "\n",
    "        is_tasmin_plottable = False\n",
    "        if \"tasmin\" in df_tasmin.columns and not df_tasmin[\"tasmin\"].isnull().all():\n",
    "            df_tasmin.set_index(\"Date\", inplace=True)\n",
    "            # Resample to annual mean\n",
    "            df_tasmin_annual = df_tasmin.resample('Y').mean().reset_index()\n",
    "            df_tasmin_annual[\"Year\"] = df_tasmin_annual[\"Date\"].dt.year\n",
    "            is_tasmin_plottable = True\n",
    "\n",
    "        if is_tasmin_plottable:\n",
    "            fig.add_trace(go.Scatter(x=df_tasmin_annual[\"Year\"], y=df_tasmin_annual[\"tasmin\"], mode=\"lines\", name=\"Annual Avg Min Temp\"))\n",
    "            fig.update_layout(\n",
    "                title=f\"Annual Average Minimum Temperature ({model}, {ssp})\",\n",
    "                xaxis_title=\"Year\",\n",
    "                yaxis_title=f\"Temperature ({tasmin_display_units})\",\n",
    "                height=400,\n",
    "                showlegend=True,\n",
    "                hovermode=\"x unified\"\n",
    "            )\n",
    "        else:\n",
    "            fig.add_annotation(\n",
    "                text=\"No plottable data for Daily Minimum Air Surface Temperature.<br>(Point may be ocean or missing data.)\",\n",
    "                showarrow=False, xref=\"paper\", yref=\"paper\", x=0.5, y=0.5, align=\"center\"\n",
    "            )\n",
    "            fig.update_layout(height=400)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    @output\n",
    "    @render_widget\n",
    "    def selected_gridbox_tasmax_plot():\n",
    "        \"\"\"\n",
    "        Renders a Plotly line plot of annual average maximum air surface temperature\n",
    "        for the selected gridbox from the NetCDF data.\n",
    "        Converts Kelvin to Fahrenheit if necessary.\n",
    "        \"\"\"\n",
    "        lat_idx, lon_idx, target_lat, target_lon_dropdown = _grid_indices()\n",
    "        ssp = selected_ssp.get()\n",
    "        model = netcdf_ds_tasmax.attrs.get(\"source_id\", \"Unknown Model\")\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        if lat_idx is None or lon_idx is None:\n",
    "            fig.add_annotation(text=\"Select a gridbox to view data.\", x=0.5, y=0.5, showarrow=False)\n",
    "            return fig\n",
    "\n",
    "        df_tasmax_raw = extract_timeseries(netcdf_ds_tasmax, lat_idx, lon_idx, variable_name=\"tasmax\")\n",
    "        tasmax_units_original = netcdf_ds_tasmax['tasmax'].attrs.get('units', 'Units Unknown')\n",
    "        df_tasmax = df_tasmax_raw.copy()\n",
    "\n",
    "        tasmax_display_units = tasmax_units_original\n",
    "        # Convert Kelvin to Fahrenheit if units are Kelvin\n",
    "        if \"tasmax\" in df_tasmax.columns and tasmax_units_original.lower() in ['k', 'kelvin']:\n",
    "            df_tasmax[\"tasmax\"] = (df_tasmax[\"tasmax\"] - 273.15) * 9/5 + 32\n",
    "            tasmax_display_units = '°F'\n",
    "\n",
    "        is_tasmax_plottable = False\n",
    "        if \"tasmax\" in df_tasmax.columns and not df_tasmax[\"tasmax\"].isnull().all():\n",
    "            df_tasmax.set_index(\"Date\", inplace=True)\n",
    "            # Resample to annual mean\n",
    "            df_tasmax_annual = df_tasmax.resample('Y').mean().reset_index()\n",
    "            df_tasmax_annual[\"Year\"] = df_tasmax_annual[\"Date\"].dt.year\n",
    "            is_tasmax_plottable = True\n",
    "\n",
    "        if is_tasmax_plottable:\n",
    "            fig.add_trace(go.Scatter(x=df_tasmax_annual[\"Year\"], y=df_tasmax_annual[\"tasmax\"], mode=\"lines\", name=\"Annual Avg Max Temp\"))\n",
    "            fig.update_layout(\n",
    "                title=f\"Annual Average Maximum Temperature ({model}, {ssp})\",\n",
    "                xaxis_title=\"Year\",\n",
    "                yaxis_title=f\"Temperature ({tasmax_display_units})\",\n",
    "                height=400,\n",
    "                showlegend=True,\n",
    "                hovermode=\"x unified\"\n",
    "            )\n",
    "        else:\n",
    "            fig.add_annotation(\n",
    "                text=\"No plottable data for Daily Maximum Air Surface Temperature.<br>(Point may be ocean or missing data.)\",\n",
    "                showarrow=False, xref=\"paper\", yref=\"paper\", x=0.5, y=0.5, align=\"center\"\n",
    "            )\n",
    "            fig.update_layout(height=400)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    # --- Campus Point Data UI Logic (CSV) ----------------------------\n",
    "    @output\n",
    "    @render.ui\n",
    "    def temp_subcategory_ui():\n",
    "        \"\"\"\n",
    "        Dynamically renders the 'Select Temperature Data Type' dropdown\n",
    "        based on the main 'Data Type' selection.\n",
    "        \"\"\"\n",
    "        if input.data_type() == \"Minimum/Maximum Temperature Projections\":\n",
    "            return ui.input_select(\"temp_subcategory\", \"Select Temperature Data Type:\", choices=[\n",
    "                \"Annual Averages\",\n",
    "                \"Extreme Heat Days and Warm Nights\",\n",
    "                \"Cooling Degree Days and Heating Degree Days\"\n",
    "            ])\n",
    "        return None\n",
    "\n",
    "    @output\n",
    "    @render.ui\n",
    "    def graph_controls_ui():\n",
    "        \"\"\"\n",
    "        Dynamically renders the year range slider and column checkboxes\n",
    "        based on 'Data Type' and 'Temperature Data Type' selections.\n",
    "        This section has been updated to include all the specified model projections.\n",
    "        \"\"\"\n",
    "        if input.data_type() == \"Minimum/Maximum Temperature Projections\" and input.temp_subcategory() == \"Annual Averages\":\n",
    "            return ui.div(\n",
    "                ui.input_slider(\"year_range\", \"Year Range:\", min=1950, max=2100, value=(1950, 2006)),\n",
    "                ui.input_checkbox_group(\n",
    "                    \"selected_columns\", \"Select Data to Display:\",\n",
    "                    choices=[\n",
    "                        \"Observed\",\n",
    "                        \"Modeled RCP 8.5 Range Min\",\n",
    "                        \"Modeled RCP 8.5 Range Max\",\n",
    "                        \"CanESM2 (Average)\",\n",
    "                        \"CNRM-CM5 (Cool/Wet)\",\n",
    "                        \"HadGEM2-ES (Warm/Dry)\",\n",
    "                        \"MIROC5 (Complement)\"\n",
    "                    ],\n",
    "                    selected=[\"Observed\"]\n",
    "                )\n",
    "            )\n",
    "        return None\n",
    "\n",
    "    @output\n",
    "    @render_widget\n",
    "    def climate_plot():\n",
    "        \"\"\"\n",
    "        Renders the Plotly climate plot for Campus Point data (CSV).\n",
    "        Displays a line plot for selected temperature projection columns.\n",
    "        This function has been updated to directly check for the exact column names.\n",
    "        \"\"\"\n",
    "        df = csv_data.get() # Get the loaded DataFrame\n",
    "        if df is None or df.empty:\n",
    "            fig = go.Figure()\n",
    "            fig.add_annotation(text=\"CSV data not loaded or empty. Please check server logs.\", x=0.5, y=0.5, showarrow=False)\n",
    "            return fig\n",
    "\n",
    "        # Plot for Minimum/Maximum Temperature Projections with Annual Averages\n",
    "        if input.data_type() == \"Minimum/Maximum Temperature Projections\" and input.temp_subcategory() == \"Annual Averages\":\n",
    "            year_min, year_max = input.year_range()\n",
    "            selected_cols = input.selected_columns()\n",
    "            if selected_cols is None:\n",
    "                selected_cols = []\n",
    "\n",
    "            filtered_df = df[(df[\"year\"] >= year_min) & (df[\"year\"] <= year_max)]\n",
    "            fig = go.Figure()\n",
    "\n",
    "            # Add a trace for each selected column, directly checking for exact column names\n",
    "            for col in selected_cols:\n",
    "                if col in filtered_df.columns: # Direct check for exact column name\n",
    "                    fig.add_trace(go.Scatter(x=filtered_df[\"year\"], y=filtered_df[col], mode=\"lines\", name=col))\n",
    "                else:\n",
    "                    print(f\"Warning: Column '{col}' not found in CSV data for plotting. Please ensure CSV column names match the selection options.\")\n",
    "\n",
    "            fig.update_layout(\n",
    "                title=f\"{input.data_type()} - {input.temp_subcategory()} at Campus Point\",\n",
    "                xaxis_title=\"Year\",\n",
    "                yaxis_title=\"Temperature (°F or as in CSV)\",\n",
    "                height=450,\n",
    "                hovermode=\"x unified\"\n",
    "            )\n",
    "            return fig\n",
    "\n",
    "        # Fallback empty figure for other data types not yet implemented\n",
    "        fig = go.Figure()\n",
    "        fig.add_annotation(text=\"Data visualization for this data type not implemented yet.\", x=0.5, y=0.5, showarrow=False)\n",
    "        return fig\n",
    "\n",
    "# Create the Shiny app instance\n",
    "app = App(app_ui, server)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
